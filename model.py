# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q772vgmo_zfETYh5Z9w6GfMoZZbqaaYA
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip /content/drive/MyDrive/DIP_project/archive.zip

import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
import glob
from tqdm import tqdm
from PIL import Image

DIR = '/content/HandGesture/images'

#Transfer 'jpg' images to an array IMG
def Dataset_loader(DIR, RESIZE, sigmaX=10):
    IMG = []
    read = lambda imname:np.asarray(Image.open(imname).convert("RGB"))
    #print(type(DIR))
    for IMAGE_NAME in tqdm(os.listdir(DIR)):
        PATH = os.path.join(DIR,IMAGE_NAME)
        _, ftype = os.path.splitext(PATH)
        if ftype == ".jpg":
            img = read(PATH)

            img = cv2.resize(img, (RESIZE,RESIZE))

            IMG.append(np.array(img))
    return IMG

call_me = np.array(Dataset_loader('/content/HandGesture/images/call_me',224))
fingers_crossed = np.array(Dataset_loader('/content/HandGesture/images/fingers_crossed',224))
okay = np.array(Dataset_loader('/content/HandGesture/images/okay',224))
paper = np.array(Dataset_loader('/content/HandGesture/images/paper',224))
peace = np.array(Dataset_loader('/content/HandGesture/images/peace',224))
rock = np.array(Dataset_loader('/content/HandGesture/images/rock',224))
rock_on = np.array(Dataset_loader('/content/HandGesture/images/rock_on',224))
scissor = np.array(Dataset_loader('/content/HandGesture/images/scissor',224))
thumbs = np.array(Dataset_loader('/content/HandGesture/images/thumbs',224))
up = np.array(Dataset_loader('/content/HandGesture/images/up',224))

call_me

"""creating the labels"""

# Create labels
call_label = np.zeros(len(call_me))
finger_label = np.ones(len(fingers_crossed))
okay_label = np.full((len(okay),), 2)
paper_label = np.full((len(paper),), 3)
peace_label = np.full((len(peace),), 4)
rock_label = np.full((len(rock),), 5)
rock_on_label = np.full((len(rock_on),), 6)
scissor_label = np.full((len(scissor),), 7)
thumbs_label = np.full((len(thumbs),), 8)
up_label = np.full((len(up),), 9)

call_label

"""shuffling the data"""

data = np.concatenate((call_me, fingers_crossed, okay, paper, peace, rock, rock_on, scissor, thumbs, up), axis = 0)
labels = np.concatenate((call_label, finger_label, okay_label, paper_label, peace_label, rock_label, rock_on_label, scissor_label, thumbs_label, up_label), axis = 0)
data = np.array(data, dtype="float32")
labels = np.array(labels, dtype="int")
data /= 255.0

# shuffle data
arr = np.arange(len(data))
np.random.shuffle(arr)
data = data[arr]
labels = labels[arr]

"""splitting the data"""

from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split

le = LabelBinarizer()
labels = le.fit_transform(labels)
counts = labels.sum(axis=0)

#spliiting the datset into training and testing
(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)

trainX

testX

trainY

testY

trainX.shape

"""Creating the model"""

from tensorflow import keras
from keras.applications import DenseNet201, ResNet50, VGG16
from keras import Model

def createBackboneModel(denseNet=False, resnet=False, vgg=False, ):
    if denseNet:
       backbone = DenseNet201(weights='imagenet',include_top=False,
                  input_shape=(224,224,3))
    if resnet:
       backbone = ResNet50(weights='imagenet',include_top=False,
                  input_shape=(224,224,3))
    if vgg:
       backbone = VGG16(weights='imagenet',include_top=False,
                  input_shape=(224,224,3))

    output = backbone.layers[-1].output
    output = keras.layers.Flatten()(output)
    backboneModel = Model(backbone.input, outputs=output)

    for layer in backboneModel.layers:
        layer.trainable = False

    return backboneModel

from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Adam

def createModel(backbone, lr=1e-4, dense=128, drpout1=0.5, drpout2=0.25):
    EPOCHS = 50
    INIT_LR = 1e-1
    BS = 128
    model = Sequential()
    model.add(backbone)
    model.add(Dropout(drpout1))
    model.add(Dense(dense, activation='relu'))
#     model.add(LeakyReLU(alpha=0.1))
#     model.add(BatchNormalization())
    model.add(Dropout(drpout2))
    model.add(Dense(10, activation='softmax'))


    model.compile(
        loss=keras.losses.categorical_crossentropy,
        optimizer=Adam(learning_rate=lr),
        metrics=['accuracy']
    )

    return model

backbone = createBackboneModel(vgg=True)
backbone.summary()

#model = createModel(backbone,lr=1e-4, drpout1=0.3, drpout2=0.2)
model = createModel(backbone)
model.summary()

# Create the model
#model = createModel(backbone)

# Fit the model
history = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=100, batch_size=30)
#history = model.fit(trainX, trainY, epochs=100)

# Evaluate the model
loss, accuracy = model.evaluate(testX, testY)
print("Test Loss:", loss)
print("Test Accuracy:", accuracy)